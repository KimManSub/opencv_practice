{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTU8uskVU3PEa5dF4lIZ8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimManSub/opencv_practice/blob/main/3_%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EA%B3%BC_%EC%9D%B4%EB%AF%B8%EC%A7%80%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인공신경망 기초"
      ],
      "metadata": {
        "id": "3gCgwLh03Hca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AND,OR,XOR 연산"
      ],
      "metadata": {
        "id": "nyFu-Mgn3-at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x1 = [0,0,1,1]\n",
        "x2 = [0,1,0,1]\n",
        "x = tf.transpose(tf.constant([x1,x2],dtype=tf.float32))\n",
        "#x1,x2 텐서플로우 사용할수 있는 형태로 변환,float32 실수형으로 변환 하고 가로세로 바꾸기\n",
        "and_y = tf.constant([0,0,0,1],dtype=tf.float32)\n",
        "or_y = tf.constant([0,1,1,1],dtype=tf.float32)\n",
        "xor_y = tf.constant([0,1,1,0],dtype=tf.float32)\n",
        "\n",
        "print(f\"x: \\n{x}\")\n",
        "print(f\"AND y:\\t{and_y}\",f\"OR  y:\\t{or_y}\",f\"XOR y:\\t{xor_y}\",sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3fbAhP94DJD",
        "outputId": "f3f40acc-5217-4e36-a4ba-d12d30b6ddfd",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: \n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "AND y:\t[0. 0. 0. 1.]\n",
            "OR  y:\t[0. 1. 1. 1.]\n",
            "XOR y:\t[0. 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AND,OR,XOR 게이트 입출력관계 시각화"
      ],
      "metadata": {
        "id": "1cYOsEhH5uyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "#1행 3열 서브 플롯 생성, 가로 15,세로 5\n",
        "\n",
        "# AND 문제\n",
        "sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=and_y, ax=axs[0])\n",
        "# x=첫번째 입력값들,y=두번째 입력값들,and게이트 출력값에 따라 다르게 표시, 서브 플롯에 그림\n",
        "axs[0].set_title(\"AND Problem\")\n",
        "axs[0].set_xlabel(\"X1\")\n",
        "axs[0].set_ylabel(\"X2\", rotation=0)\n",
        "\n",
        "# OR 문제\n",
        "sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=or_y, ax=axs[1])\n",
        "axs[1].set_title(\"OR Problem\")\n",
        "axs[1].set_xlabel(\"X1\")\n",
        "axs[1].set_ylabel(\"X2\", rotation=0)\n",
        "\n",
        "# XOR 문제\n",
        "sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=xor_y, ax=axs[2])\n",
        "axs[2].set_title(\"XOR Problem\")\n",
        "axs[2].set_xlabel(\"X1\")\n",
        "axs[2].set_ylabel(\"X2\", rotation=0)\n",
        "plt.tight_layout() #간격사이 자동조정\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "2FCN66j74WBW",
        "outputId": "80398e68-e677-4cb4-f404-d61508616424"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 퍼셉트론"
      ],
      "metadata": {
        "id": "YuGex38E69DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 모델 정의\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_dim=2, activation='sigmoid')\n",
        "])\n",
        "# Sequential 층을 순차적으로 쌓는 가장 기본적인 신경망 모델\n",
        "# Dense 완전연결 뉴런층(fully connected layer) 생성\n",
        "# input_dim=2 입력(x1,x2)\n",
        "# 시그모이드 활성화 함수 (0~1값 사이 출력하는걸 사용함.)"
      ],
      "metadata": {
        "id": "AlmYSOpi7WgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81ce89e-405e-4c8d-94b9-d87b2ff37c91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AND 연산\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'],)\n",
        "\n",
        "#SGD(경사하강법)= 틀린부분 학습하고 정답에 가까워짐\n",
        "# learning_rate=1.0 = 숫자가 크면 더 크게 수정, 작으면 작게 수정\n",
        "# 손실함수-> 모델이 틀린정도를 측정하는 방법 loss='binary_crossentropy'\n",
        "# 학습된 모델의 최종 손실값과 정확도를 계산\n",
        "# 학습 데이터로 평가\n"
      ],
      "metadata": {
        "id": "qtJu22i27vJJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, and_y, epochs=100, batch_size=4)\n",
        "# 학습된 모델로 입력 데이터에 대한 예측 수행\n",
        "# 0~1 사이의 실수값으로 출력 (0.5를 기준으로 0 또는 1로 해석)\n",
        "# x = 입력데이터,and_y = 정답 데이터([0,0,0,1]),전체 데이터쎗을 100번 학습, batch_size=4  한번에 4개의 데이터로 학습\n",
        "#예시( 입력 [0,0],[0,1],[1,0],[1,1]) --> 이게 4개 1배치 일때 예측값이 [0.2,0.3,0.4,0.8] 이면 정답기반 [0,0,0,1] 기반으로 손실 계산함.\n",
        "\n",
        "\n",
        "# 모델 평가\n",
        "loss, accuracy = model.evaluate(x, and_y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "# 학습된 모델의 최종 손실값과 정확도 계산 망약 예측한 값이 정답이랑 같으면 1 아니면 0\n",
        "# 학습데이터 평가\n",
        "\n",
        "\n",
        "# 예측\n",
        "predictions = model.predict(x)\n",
        "print(f'Predictions:\\n{predictions}')\n",
        "#학습된 모델로 데이터에 대한 예측\n",
        "#0~1사이의 실수값으로 출력(0.5를 기준으로 0또는 1로 해석)\n",
        "\n",
        "# 가장 단순한 형태의 퍼셉트론 구현 (은닉층 없음)\n",
        "# AND 게이트는 선형 분리 가능하므로 이 단순한 구조로도 학습 가능\n",
        "# 실제 딥러닝에서는 더 복잡한 문제를 다루므로 보통 더 많은 층과 뉴런을 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vgtECOgX76Oe",
        "outputId": "484a0f9e-1260-4de2-935a-a42a1042a09c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774ms/step - accuracy: 0.7500 - loss: 0.8172\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.7777\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.7419\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7500 - loss: 0.7091\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.7500 - loss: 0.6790\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.7500 - loss: 0.6513\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.7500 - loss: 0.6256\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6017\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7500 - loss: 0.5796\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.5591\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7500 - loss: 0.5400\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7500 - loss: 0.5221\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.7500 - loss: 0.5055\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.4900\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7500 - loss: 0.4755\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7500 - loss: 0.4618\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.7500 - loss: 0.4490\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7500 - loss: 0.4370\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.4257\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.4150\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7500 - loss: 0.4049\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.3953\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.3862\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 0.3776\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 0.3695\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.3617\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 1.0000 - loss: 0.3542\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 1.0000 - loss: 0.3472\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.3404\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.3339\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.3277\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.3218\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.3160\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 1.0000 - loss: 0.3106\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.3053\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.3002\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2953\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.2906\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2860\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2816\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2774\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2733\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2693\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2654\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2617\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2581\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2545\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.2511\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.2478\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2446\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.2414\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.2384\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.2354\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.2325\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2297\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.2270\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2243\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2217\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2191\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.2166\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.2142\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.2118\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.2095\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2072\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.2050\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.2028\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.2007\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.1986\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1966\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1946\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1926\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1907\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.1889\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1870\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1852\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1835\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1817\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1800\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1784\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1767\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1751\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1735\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1720\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1705\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.1690\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1675\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1661\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1646\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1632\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1619\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1605\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1592\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1579\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1566\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1553\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1541\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1529\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1517\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1505\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1493\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.1482\n",
            "Loss: 0.1481676995754242, Accuracy: 1.0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Predictions:\n",
            "[[0.00927851]\n",
            " [0.15451494]\n",
            " [0.15356696]\n",
            " [0.7797515 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OR 연산\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_dim=2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, or_y, epochs=100, batch_size=4)\n",
        "\n",
        "loss, accuracy = model.evaluate(x, or_y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "predictions = model.predict(x)\n",
        "print(f'X:\\n{x}')\n",
        "print(f'Predictions:\\n{predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2UnQGiqIMXo",
        "outputId": "ea2791a0-6177-48cb-9eea-0241ae52e292",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.7500 - loss: 0.6822\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.5582\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.4938\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.4551\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7500 - loss: 0.4285\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.4084\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.3919\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.3777\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.3650\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7500 - loss: 0.3533\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.3426\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.3325\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7500 - loss: 0.3230\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.3141\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.3056\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.2975\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7500 - loss: 0.2898\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.2824\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7500 - loss: 0.2754\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2688\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.2624\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.2563\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.2504\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.2448\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.2395\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2343\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.2294\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.2247\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.2201\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.2157\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2115\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.2075\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.2035\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1998\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.1961\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1926\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1892\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1860\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1828\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.1797\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.1768\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.1739\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1711\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1684\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.1658\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.1633\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1608\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.1584\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.1561\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.1538\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1516\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1495\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1474\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.1454\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1434\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.1415\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.1396\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1378\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1360\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1343\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.1326\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1309\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1293\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1277\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.1262\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1247\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1232\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1218\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.1204\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1190\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1177\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1163\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1151\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.1138\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.1126\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1113\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.1102\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.1090\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1079\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1067\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1057\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1046\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1035\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1025\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1015\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1005\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0995\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0986\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0976\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0967\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0958\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0949\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0940\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0932\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0923\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0915\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0907\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0899\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0891\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0883\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 1.0000 - loss: 0.0875\n",
            "Loss: 0.08754801750183105, Accuracy: 1.0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "X:\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "Predictions:\n",
            "[[0.18272924]\n",
            " [0.92374367]\n",
            " [0.9344541 ]\n",
            " [0.998707  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# XOR 연산\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_dim=2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, xor_y, epochs=100, batch_size=4)\n",
        "\n",
        "loss, accuracy = model.evaluate(x, xor_y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "predictions = model.predict(x)\n",
        "print(f'X:\\n{x}')\n",
        "print(f'Predictions:\\n{predictions}')\n",
        "\n",
        "#다층 퍼셉트론이없어 잘안됨\n",
        "\n",
        "#단일층 구조와 다층 구조의 차이점\n",
        "\n",
        "# 단일층 구조 - 입력데이터 선형적으로 분리하는데만 적합함\n",
        "# 다층 구조 - 은닉층 추가 되면서 모델 표현력 증가 (비선형 활성화 함수 ReLu,tanh 등) 선형적으로 구분할수 없을때 사용\n",
        "# 구조\n",
        "#단일층 구조 :  입력 -> 출력 (제한적)\n",
        "#다층 구조 :  입력  -> 은닉층 -> 출력 ( 고차원적, 복잡한 표현 가능)\n",
        "\n",
        "\n",
        "#여기서 은닉층--> 입력 데이터를 조합하여 학습 가능한 특징을 생성함. 단순히 입력 데이터를 전달하는게 아닌 복잡한 변환과 학습을 통해 문제 해결함.\n",
        "# 가중치(Weights)와 바이어스(Bias) 를 통해서 문제를 해결하는데\n",
        "# 가중치는 데이터의 중요도를 나타내고 (더 크게 반영할건지?, 작게 반영할껀지)\n",
        "# 바이어스는 (가중치에 곱해진결과) 선형 변화에 일정한 값을 3ㅓ더해 데이터에 더 유연하게 처리 할수 있게 함.\n",
        "\n",
        "# 활성화함수종류\n",
        "\n",
        "# ReLU: 양수는 그대로 출력, 음수는 0으로 출력. 학습 속도가 빠르고, 잘 작동\n",
        "# Sigmoid: 0~1 사이의 값으로 출력. 확률을 표현할 때 자주 사용\n",
        "# Tanh: -1~1 사이의 값으로 출력. 중심값이 0이라 대칭적인 데이터를 처리하기 적합\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nKMtzJXyIisX",
        "outputId": "1187cd7b-79ba-40ff-c12f-782659a02338"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.5000 - loss: 0.7834\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.7431\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.7242\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5000 - loss: 0.7153\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7108\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.7082\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.7063\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7049\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.7037\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7027\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7017\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7009\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.7002\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6995\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5000 - loss: 0.6989\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6983\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6979\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6974\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6970\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6967\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6963\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6960\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6958\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6955\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.6953\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6951\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6949\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6948\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6946\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6945\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6944\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6943\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6942\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6941\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6940\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6939\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5000 - loss: 0.6938\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5000 - loss: 0.6937\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5000 - loss: 0.6936\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.6936\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6935\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6934\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6933\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.7500 - loss: 0.6932\n",
            "Loss: 0.6931506395339966, Accuracy: 0.75\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "X:\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "Predictions:\n",
            "[[0.5021328 ]\n",
            " [0.50014424]\n",
            " [0.5005252 ]\n",
            " [0.49853665]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#다층 퍼셉트론"
      ],
      "metadata": {
        "id": "yMpcLYlILdx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(16, input_dim=2, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, xor_y, epochs=100, batch_size=4)\n",
        "\n",
        "loss, accuracy = model.evaluate(x, xor_y)\n",
        "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "predictions = model.predict(x)\n",
        "print(f'X:\\n{x}')\n",
        "print(f'Predictions:\\n{predictions}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRvPDAJ_Lcsi",
        "outputId": "b6df96c0-f7ad-4aaa-a0c8-3bd5c3772f60",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.5000 - loss: 0.6884\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7500 - loss: 0.6487\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.6236\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7500 - loss: 0.6038\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7500 - loss: 0.5823\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7500 - loss: 0.5682\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.5477\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.5269\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.5084\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.4872\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.4750\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.4514\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.4257\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.4208\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.3967\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.3636\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3538\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.3328\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 1.0000 - loss: 0.3173\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2943\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2720\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.2584\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.2424\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.2381\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.2238\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.2108\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.1950\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1814\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.1697\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1658\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1596\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.1491\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.1417\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1336\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1301\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.1218\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.1156\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.1114\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1060\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1023\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.1003\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0966\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0922\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0887\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0847\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0814\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0792\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0776\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0743\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0714\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0692\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0684\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0667\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0641\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0622\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.0612\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0588\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 1.0000 - loss: 0.0570\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0554\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0540\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 1.0000 - loss: 0.0527\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0513\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 1.0000 - loss: 0.0501\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0504\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0487\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0472\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0460\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0449\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0439\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0430\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0421\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0411\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0403\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0398\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0391\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0384\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0378\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0368\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.0359\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0354\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0348\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0341\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 0.0335\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.0329\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0326\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0319\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0313\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0309\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0307\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0300\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0294\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0290\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0286\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.0281\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0276\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0274\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0269\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0265\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.0261\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0257\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0255\n",
            "Loss: 0.025538472458720207, Accuracy: 1.0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "X:\n",
            "[[0. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 1.]]\n",
            "Predictions:\n",
            "[[0.06896442]\n",
            " [0.98834765]\n",
            " [0.98797613]\n",
            " [0.006855  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "인공지능 모델의 설계 및 학습"
      ],
      "metadata": {
        "id": "sw1a4s5MMO8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 독립 변수 X 값 생성\n",
        "import tensorflow as tf\n",
        "\n",
        "x = tf.random.uniform(shape=[100], minval=1, maxval=4)\n",
        "#1~4사이 균일분포를 지닌 100개의 x값 생성\n",
        "print(x)"
      ],
      "metadata": {
        "id": "9TD2LnK7NZ6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9180c83c-d827-4f29-80ee-1c55ef6aefcf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[1.4878867 3.622806  3.457089  1.787832  1.4136707 1.3392129 2.0237384\n",
            " 1.7427387 3.7237673 3.621865  1.0216597 3.117598  2.1020079 3.6472688\n",
            " 2.6265826 2.7352424 3.8973646 3.4152799 3.8795388 2.6427832 3.2376668\n",
            " 1.2014425 1.3595651 3.5306535 2.634304  2.4562857 2.1369226 3.512229\n",
            " 1.5163388 1.44896   3.975762  1.2252308 1.6269842 2.3398278 2.9646573\n",
            " 3.1780975 1.3780892 2.1717615 3.7243326 3.9722161 2.078979  1.9189967\n",
            " 2.341118  1.6187248 2.5576947 2.2697015 3.1558962 1.117808  2.574978\n",
            " 3.6583853 1.8550893 3.297987  2.027935  1.8868438 3.1012318 3.4526405\n",
            " 2.4022884 1.2762325 2.1322565 2.6954942 1.147333  2.5005012 2.8896627\n",
            " 2.6014676 2.469514  1.9655473 1.8309816 1.7100548 2.1432452 2.0732055\n",
            " 2.5762644 3.3858194 2.7623665 3.0890589 1.0816854 2.920667  1.6763734\n",
            " 2.3872604 1.8315141 3.2020383 2.3455484 2.677291  2.0407877 3.8714275\n",
            " 1.5707072 1.4267395 2.5493426 2.3229332 1.2997458 3.1236508 2.8331866\n",
            " 3.0717235 2.2828133 2.538606  3.919642  3.8358083 3.3108816 1.5222629\n",
            " 3.3995771 1.3261083], shape=(100,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 관계가 있는 종속 변수 Y 값 생성\n",
        "slope = 1.5\n",
        "intercept = 3\n",
        "\n",
        "epsilon = tf.random.truncated_normal(shape=[100], mean=0, stddev=0.3)\n",
        "#평균 0, 표준편차 0.3 노이즈 추가\n",
        "y = slope * x + intercept + epsilon\n",
        "#실제 선형관계 1.5x+3= y\n",
        "print(y)"
      ],
      "metadata": {
        "id": "xYB7FDMCNbri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6cbbe16-e39b-457a-bff8-fcf467b31724"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[4.9269905 8.923595  8.075091  5.5405664 5.21864   5.5312667 5.5606704\n",
            " 5.291063  8.294778  8.504734  4.0642166 8.016062  5.6381454 8.84952\n",
            " 7.2911615 6.705819  8.317947  7.5521207 8.714999  7.1995544 7.4196672\n",
            " 4.657204  4.940528  8.736226  7.1065674 6.7850757 6.5649247 8.372388\n",
            " 5.798127  5.328084  8.414943  4.707556  5.213453  6.4627604 7.7258873\n",
            " 8.212984  5.5291467 6.4061813 8.235968  8.457225  6.6017294 5.8733773\n",
            " 6.3743634 5.4150305 6.8963537 6.368758  7.999251  4.402625  6.672975\n",
            " 8.652013  5.788286  8.122056  6.201503  5.744036  8.179916  8.130158\n",
            " 6.3791666 5.131012  6.0526958 6.739741  4.738052  6.8732424 7.6850624\n",
            " 6.8220053 6.5232654 5.35809   5.498338  5.756218  6.0736003 6.1072483\n",
            " 7.210763  8.131711  7.361188  7.4335284 4.65106   7.152001  5.6986427\n",
            " 7.0000663 5.7150908 7.938421  6.205612  7.0712337 5.945957  9.198898\n",
            " 5.7176    5.34099   6.288186  6.627262  4.8935127 7.815476  7.3843937\n",
            " 7.5944347 6.7294626 6.7724767 8.939624  8.914883  7.825484  5.542325\n",
            " 8.05318   5.3216095], shape=(100,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 맷플로립을 사용한 데이터 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "#darkgrid 사용\n",
        "plt.scatter(x, y)\n",
        "plt.xlabel('Feature (X)')\n",
        "plt.ylabel('Label (Y)')\n",
        "plt.title('sythetic dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "92Pc_3xINdIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "7cf44ad4-19ab-4267-d7cc-7c5c0fedaf4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "텐서플로로 선형 데이터 모델링\n"
      ],
      "metadata": {
        "id": "fbKFxEO0Nd--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 설계"
      ],
      "metadata": {
        "id": "bAKE58ynNlsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT9uKrEGQTg_",
        "outputId": "6bd34914-5c85-44a5-c263-4bdf42a83e71"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade tensorflow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SzK2SnW3QXe8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow와 Keras를 불러오기\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 확인\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Dense layer loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkjCtjdDQnyS",
        "outputId": "f3692736-17fd-4d96-a388-a0a76c9c8586"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Dense layer loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "# Keras Sequenial 기본신경망 신경만 뉴런 밀집층"
      ],
      "metadata": {
        "id": "h_wVjXg-Pr1v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "# Dense층 -> 모든 뉴런이 이전 층의 모든 뉴련과 연결되는 기본적인 신경망 층(선형)"
      ],
      "metadata": {
        "id": "m0oIgdTuPyL6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "#모델 인스턴스 생성 - 레이어들을 순차 추가가능\n",
        "model.add(Dense(1, input_shape=(1,)))\n",
        "# 출력뉴런 1개 , 입력특성 1개 지정\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "#학습모델 설정,평균 제곱 오차를 손실 함수로 사용(회귀문제 적합) , 확률적 경사 하강법을 옵티마이저로 사용"
      ],
      "metadata": {
        "id": "iH2Nk5hUNqtT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델학습"
      ],
      "metadata": {
        "id": "oIlpXg9ZNxKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.reshape(x, (-1, 1))\n",
        "#-1 자동크기계산, 각행에 1의 특성을가지도록 지정\n",
        "x_train.shape\n",
        "# 변환 전: [1.2, 2.3, 3.1, ..., 3.8]  # 1차원 배열\n",
        "\n",
        "# 변환 후: [[1.2],\n",
        "#           [2.3],\n",
        "#           [3.1],\n",
        "#           ...,\n",
        "#           [3.8]]  # 2차원 배열 (100행 1열)\n"
      ],
      "metadata": {
        "id": "Y1Yq_qccNzLV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9710e18-edb5-4587-f178-24c9a7945293"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y, epochs=300)\n",
        "#점점 오차율이 감소해야 정상"
      ],
      "metadata": {
        "id": "Wqrlpqw5N0mG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f627987a-4982-4997-f5da-686bb5793b46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.3372  \n",
            "Epoch 2/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.5877  \n",
            "Epoch 3/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.0070 \n",
            "Epoch 4/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2220 \n",
            "Epoch 5/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7278 \n",
            "Epoch 6/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5723 \n",
            "Epoch 7/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5495 \n",
            "Epoch 8/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5064 \n",
            "Epoch 9/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5176 \n",
            "Epoch 10/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5501 \n",
            "Epoch 11/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5139 \n",
            "Epoch 12/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5297 \n",
            "Epoch 13/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4528 \n",
            "Epoch 14/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4860 \n",
            "Epoch 15/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4568 \n",
            "Epoch 16/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4943 \n",
            "Epoch 17/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.5292 \n",
            "Epoch 18/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4841  \n",
            "Epoch 19/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4506  \n",
            "Epoch 20/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4643 \n",
            "Epoch 21/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4738 \n",
            "Epoch 22/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4332 \n",
            "Epoch 23/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4124 \n",
            "Epoch 24/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4718 \n",
            "Epoch 25/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4337 \n",
            "Epoch 26/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4407 \n",
            "Epoch 27/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4325 \n",
            "Epoch 28/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4182 \n",
            "Epoch 29/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4478 \n",
            "Epoch 30/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.4104 \n",
            "Epoch 31/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3994 \n",
            "Epoch 32/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4242 \n",
            "Epoch 33/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4168 \n",
            "Epoch 34/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3797 \n",
            "Epoch 35/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4005 \n",
            "Epoch 36/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3879 \n",
            "Epoch 37/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3548 \n",
            "Epoch 38/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3568 \n",
            "Epoch 39/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3563 \n",
            "Epoch 40/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3819 \n",
            "Epoch 41/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3440 \n",
            "Epoch 42/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3765 \n",
            "Epoch 43/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3569 \n",
            "Epoch 44/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3538 \n",
            "Epoch 45/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3581 \n",
            "Epoch 46/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3470 \n",
            "Epoch 47/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3411 \n",
            "Epoch 48/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3302 \n",
            "Epoch 49/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3380 \n",
            "Epoch 50/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3408 \n",
            "Epoch 51/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3118 \n",
            "Epoch 52/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3314 \n",
            "Epoch 53/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2870 \n",
            "Epoch 54/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3226 \n",
            "Epoch 55/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3027 \n",
            "Epoch 56/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3091 \n",
            "Epoch 57/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3234 \n",
            "Epoch 58/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3067 \n",
            "Epoch 59/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3189 \n",
            "Epoch 60/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2737 \n",
            "Epoch 61/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2859 \n",
            "Epoch 62/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3167 \n",
            "Epoch 63/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3029 \n",
            "Epoch 64/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2822 \n",
            "Epoch 65/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2969 \n",
            "Epoch 66/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2998 \n",
            "Epoch 67/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2766 \n",
            "Epoch 68/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2618 \n",
            "Epoch 69/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2858 \n",
            "Epoch 70/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2833 \n",
            "Epoch 71/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2670 \n",
            "Epoch 72/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2711 \n",
            "Epoch 73/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2570 \n",
            "Epoch 74/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2861 \n",
            "Epoch 75/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2569 \n",
            "Epoch 76/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2552 \n",
            "Epoch 77/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2628 \n",
            "Epoch 78/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2573 \n",
            "Epoch 79/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2454 \n",
            "Epoch 80/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2569 \n",
            "Epoch 81/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2417 \n",
            "Epoch 82/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2259 \n",
            "Epoch 83/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2336 \n",
            "Epoch 84/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2403 \n",
            "Epoch 85/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2340 \n",
            "Epoch 86/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2242 \n",
            "Epoch 87/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2159 \n",
            "Epoch 88/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2110 \n",
            "Epoch 89/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2175 \n",
            "Epoch 90/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2248 \n",
            "Epoch 91/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2282 \n",
            "Epoch 92/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2278 \n",
            "Epoch 93/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2340 \n",
            "Epoch 94/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2306 \n",
            "Epoch 95/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2158 \n",
            "Epoch 96/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2140 \n",
            "Epoch 97/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2049 \n",
            "Epoch 98/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2200 \n",
            "Epoch 99/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2064 \n",
            "Epoch 100/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2106 \n",
            "Epoch 101/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2100 \n",
            "Epoch 102/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1944 \n",
            "Epoch 103/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2076 \n",
            "Epoch 104/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2214 \n",
            "Epoch 105/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2064 \n",
            "Epoch 106/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1998 \n",
            "Epoch 107/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1886 \n",
            "Epoch 108/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1693 \n",
            "Epoch 109/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1826 \n",
            "Epoch 110/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1961 \n",
            "Epoch 111/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1926 \n",
            "Epoch 112/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1811 \n",
            "Epoch 113/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1984 \n",
            "Epoch 114/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1649 \n",
            "Epoch 115/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1633 \n",
            "Epoch 116/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1672 \n",
            "Epoch 117/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1752 \n",
            "Epoch 118/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1785 \n",
            "Epoch 119/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1854 \n",
            "Epoch 120/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1631 \n",
            "Epoch 121/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1702 \n",
            "Epoch 122/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1684 \n",
            "Epoch 123/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1678 \n",
            "Epoch 124/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1686 \n",
            "Epoch 125/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1688 \n",
            "Epoch 126/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1533 \n",
            "Epoch 127/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1672 \n",
            "Epoch 128/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1687 \n",
            "Epoch 129/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1578 \n",
            "Epoch 130/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1551 \n",
            "Epoch 131/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1636 \n",
            "Epoch 132/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1622 \n",
            "Epoch 133/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1388 \n",
            "Epoch 134/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1583 \n",
            "Epoch 135/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1410 \n",
            "Epoch 136/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1491 \n",
            "Epoch 137/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1537 \n",
            "Epoch 138/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1539 \n",
            "Epoch 139/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1489 \n",
            "Epoch 140/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1456 \n",
            "Epoch 141/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1498 \n",
            "Epoch 142/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1634 \n",
            "Epoch 143/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1576 \n",
            "Epoch 144/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1497 \n",
            "Epoch 145/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1499 \n",
            "Epoch 146/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1503 \n",
            "Epoch 147/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1502 \n",
            "Epoch 148/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1442 \n",
            "Epoch 149/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1424 \n",
            "Epoch 150/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1421 \n",
            "Epoch 151/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1292 \n",
            "Epoch 152/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1397 \n",
            "Epoch 153/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1336 \n",
            "Epoch 154/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1447 \n",
            "Epoch 155/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1383 \n",
            "Epoch 156/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1330 \n",
            "Epoch 157/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1280 \n",
            "Epoch 158/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1355 \n",
            "Epoch 159/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1384 \n",
            "Epoch 160/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1142 \n",
            "Epoch 161/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1220 \n",
            "Epoch 162/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1410 \n",
            "Epoch 163/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1173 \n",
            "Epoch 164/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1221 \n",
            "Epoch 165/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1325 \n",
            "Epoch 166/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1176 \n",
            "Epoch 167/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1258 \n",
            "Epoch 168/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1178 \n",
            "Epoch 169/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1205 \n",
            "Epoch 170/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1281  \n",
            "Epoch 171/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1109 \n",
            "Epoch 172/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1307 \n",
            "Epoch 173/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1219 \n",
            "Epoch 174/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1179  \n",
            "Epoch 175/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1255 \n",
            "Epoch 176/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1125 \n",
            "Epoch 177/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1171 \n",
            "Epoch 178/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1125  \n",
            "Epoch 179/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1279 \n",
            "Epoch 180/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1408 \n",
            "Epoch 181/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1187  \n",
            "Epoch 182/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1314  \n",
            "Epoch 183/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1228 \n",
            "Epoch 184/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1140  \n",
            "Epoch 185/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1132  \n",
            "Epoch 186/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1261 \n",
            "Epoch 187/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1180 \n",
            "Epoch 188/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1105 \n",
            "Epoch 189/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1146 \n",
            "Epoch 190/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1260 \n",
            "Epoch 191/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1126 \n",
            "Epoch 192/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1051 \n",
            "Epoch 193/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1052 \n",
            "Epoch 194/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1183 \n",
            "Epoch 195/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1230 \n",
            "Epoch 196/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1175 \n",
            "Epoch 197/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0982 \n",
            "Epoch 198/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1256 \n",
            "Epoch 199/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1189 \n",
            "Epoch 200/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1088 \n",
            "Epoch 201/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1038 \n",
            "Epoch 202/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1173 \n",
            "Epoch 203/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1123 \n",
            "Epoch 204/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1025 \n",
            "Epoch 205/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1079 \n",
            "Epoch 206/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0983 \n",
            "Epoch 207/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0969 \n",
            "Epoch 208/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1079 \n",
            "Epoch 209/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1108 \n",
            "Epoch 210/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1221 \n",
            "Epoch 211/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1034 \n",
            "Epoch 212/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1048 \n",
            "Epoch 213/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0997 \n",
            "Epoch 214/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1095 \n",
            "Epoch 215/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1140 \n",
            "Epoch 216/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1034  \n",
            "Epoch 217/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0905 \n",
            "Epoch 218/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1081 \n",
            "Epoch 219/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1069 \n",
            "Epoch 220/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1000 \n",
            "Epoch 221/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0990 \n",
            "Epoch 222/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1153 \n",
            "Epoch 223/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0951 \n",
            "Epoch 224/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1005 \n",
            "Epoch 225/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1009 \n",
            "Epoch 226/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1061 \n",
            "Epoch 227/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1009 \n",
            "Epoch 228/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1042 \n",
            "Epoch 229/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1015 \n",
            "Epoch 230/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1053 \n",
            "Epoch 231/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0964 \n",
            "Epoch 232/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1001 \n",
            "Epoch 233/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1040 \n",
            "Epoch 234/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1013 \n",
            "Epoch 235/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0916 \n",
            "Epoch 236/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1026 \n",
            "Epoch 237/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1020 \n",
            "Epoch 238/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0912 \n",
            "Epoch 239/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1069 \n",
            "Epoch 240/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0938 \n",
            "Epoch 241/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0934 \n",
            "Epoch 242/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0999 \n",
            "Epoch 243/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1071 \n",
            "Epoch 244/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0915 \n",
            "Epoch 245/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1043 \n",
            "Epoch 246/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0965 \n",
            "Epoch 247/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0984 \n",
            "Epoch 248/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1011 \n",
            "Epoch 249/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1055 \n",
            "Epoch 250/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0946 \n",
            "Epoch 251/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0959 \n",
            "Epoch 252/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0997  \n",
            "Epoch 253/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0868 \n",
            "Epoch 254/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0949 \n",
            "Epoch 255/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0976 \n",
            "Epoch 256/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0959 \n",
            "Epoch 257/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0842 \n",
            "Epoch 258/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0897 \n",
            "Epoch 259/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0974 \n",
            "Epoch 260/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0935 \n",
            "Epoch 261/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0894 \n",
            "Epoch 262/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0859 \n",
            "Epoch 263/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0866 \n",
            "Epoch 264/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0922 \n",
            "Epoch 265/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0996 \n",
            "Epoch 266/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0894 \n",
            "Epoch 267/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0988 \n",
            "Epoch 268/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0902 \n",
            "Epoch 269/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0889 \n",
            "Epoch 270/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0986 \n",
            "Epoch 271/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0978 \n",
            "Epoch 272/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0960 \n",
            "Epoch 273/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0942 \n",
            "Epoch 274/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0937 \n",
            "Epoch 275/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0983 \n",
            "Epoch 276/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0923 \n",
            "Epoch 277/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0857 \n",
            "Epoch 278/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0935 \n",
            "Epoch 279/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0842 \n",
            "Epoch 280/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0962 \n",
            "Epoch 281/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0952 \n",
            "Epoch 282/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0900 \n",
            "Epoch 283/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0901  \n",
            "Epoch 284/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0939 \n",
            "Epoch 285/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0946 \n",
            "Epoch 286/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0823 \n",
            "Epoch 287/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0929 \n",
            "Epoch 288/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0848 \n",
            "Epoch 289/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0901 \n",
            "Epoch 290/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0913 \n",
            "Epoch 291/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0878 \n",
            "Epoch 292/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0799 \n",
            "Epoch 293/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0924 \n",
            "Epoch 294/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0791 \n",
            "Epoch 295/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 \n",
            "Epoch 296/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0863 \n",
            "Epoch 297/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0890 \n",
            "Epoch 298/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0837 \n",
            "Epoch 299/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0908 \n",
            "Epoch 300/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0913 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights, bias = model.get_weights()\n",
        "print(\"Weights (Slope):\", weights)\n",
        "print(\"Bias (Intercept):\", bias)"
      ],
      "metadata": {
        "id": "BziVKC74MctP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5096a7e2-0519-4650-f11c-807499c41ef2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights (Slope): [[1.5817183]]\n",
            "Bias (Intercept): [2.7902343]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 합성곱 신경망\n",
        "\n",
        "# #CNN의 구성요소\n",
        "# (1) 합성곱(Convolution) 층\n",
        "# 합성곱 층에 존재하는 사각형 모양의 사각형 모양의 가중치 필터 = 합성곱 필터\n",
        "# 이 필터가 입력된 이미지 데이터와 연산됨\n",
        "# 역할: 이미지의 로컬 영역(작은 패치)을 살펴보면서 패턴을 학습\n",
        "\n",
        "# 작동 원리:\n",
        "# 필터 : 이미지 위를 슬라이딩하며 특정 패턴(엣지, 코너 등)을 탐지 ★여러 커널의 집합★\n",
        "# 가로*세로*필터 즉, 3차원임 -->  feature라하고 , 결과물 은 3차원 백터이므로 feature vector,Fature Map(특징맵) 이라함.\n",
        "# 예시: 3x3 필터가 5x5 이미지에 적용되면 3x3 영역마다 연산 수행 → 더 작은 특징 맵 생성.\n",
        "# 이미지의 특정 패턴(엣지,코너 등)을 감지하는 작은 행렬, 학습과정에서 데이터를 가장 잘 설명하는 값으로 조정됨\n",
        "# - 좀더 고차원 엣지, 코너 또는 더 복잡한 수준 탐지\n",
        "# 하나의 특징맵을 생성하기 위해 여러 커널을 포함하는 집합\n",
        "# 보통 3X3, 5X5, 7X7 로 구성  (너무작으면 학습 어려움, 너무 크면 중요한정보 놓침)\n",
        "\n",
        "# CNN에서 초반 합성곱층은 **로우 레벨 특징(엣지, 코너 등)**을 학습하고, 뒤로 갈수록 **하이레벨 특징(더 추상적인 개념, 예: 얼굴, 물체 등)**을 학습\n",
        "\n",
        "# 초기 층: 간단한 패턴(엣지, 텍스처)을 학습\n",
        "# 중간 층: 더 복잡한 구조(선, 도형 등)를 학습\n",
        "# 마지막 층: 고수준 특징(객체, 얼굴 등)을 학습\n",
        "\n",
        "\n",
        "#커널 -> 이미지 합성곱(convolution)연산을 수행하는 작은 행렬\n",
        "# - 역활 임력 이미지 위를 움직이면서 특정 패턴이나 특징 감지\n",
        "# -엣지,텍스쳐, 모양 등 로우레벨 특징 감지\n",
        "\n",
        "# - 스프라이드\n",
        "# 필터가 이동하는 간격 보통 1사용 , 더 큰값을 사용하면 특징맵 크기 작아짐\n",
        "\n",
        "# - 패딩\n",
        "# 필터를 적용할 때, 이미지 가장 자리 데이터를 처리하는 방식\n",
        "\n",
        "# (2) 활성화 함수 (ReLU, Rectified Linear Unit)\n",
        "# 역할: 비선형성을 추가하여 신경망이 복잡한 관계를 학습할 수 있도록 도움.\n",
        "# 수식:\n",
        "# 𝑓(𝑥)=max(0,𝑥)f(x)=max(0,x) (0보다 작으면 0, 크면 그대로 통과).\n",
        "\n",
        "# (3) 풀링(Pooling) 층\n",
        "# 역할: 특징 맵의 크기를 줄여 계산량을 감소시키고 중요한 정보를 요약.\n",
        "# 종류:\n",
        "# 최대 풀링(Max Pooling): 각 영역에서 가장 큰 값을 선택.\n",
        "# 평균 풀링(Average Pooling): 각 영역의 평균 값을 선택.\n",
        "# 장점: 위치 변화(이미지가 약간 이동해도)에도 강건한 특징을 학습.\n",
        "\n",
        "# (4) 완전 연결(Dense) 층\n",
        "# 역할: 학습된 특징을 기반으로 최종 분류 또는 예측 수행.\n",
        "# 특징 맵을 1차원 벡터로 펼친(flatten) 뒤, 여러 개의 뉴런과 연결.\n",
        "\n",
        "#간단한 CNN 구성요소\n",
        "#Input Image → Conv → ReLU → Pool → Conv → ReLU → Pool → Flatten → Dense → Output\n",
        "\n",
        "# 왜 32*32로 작동하는가??\n",
        "# CNN 모델에서의 효율성: 32x32 크기는 작은 이미지 처리에 적합하고, 적절한 계산량을 유지하면서도 유용한 특징을 추출\n",
        "# 이미지를 줄이는 이유 : 계산 효율성, 메모리 절약, 모델 학습 속도 향상, 과적합 방지\n",
        "\n",
        "\n",
        "\n",
        "# CNN을 배우면 할 수 있는 것\n",
        "# 이미지 분류\n",
        "# 객체 탐지\n",
        "# 이미지 생성 (GAN과 결합)\n",
        "# 스타일 전이 (예: 사진을 그림처럼 변환)"
      ],
      "metadata": {
        "id": "qJZ84Ty8Sl6h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝을 활용한 이미지 처리"
      ],
      "metadata": {
        "id": "TtgCA7LYWROB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 분류"
      ],
      "metadata": {
        "id": "OoHZN_KiWVH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이미지 분류를 위한 데이터 전처리"
      ],
      "metadata": {
        "id": "Fvkb38vLWXIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matplotlib의 pyplot 모듈을 가져옴. 데이터 시각화를 위해 사용.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CIFAR-10 데이터셋 로드 (사전 학습된 데이터셋 제공)\n",
        "# CIFAR-10은 32x32 크기의 60,000개 컬러 이미지로 구성된 데이터셋이며, 10개의 클래스(비행기, 자동차, 새 등)를 포함.\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Keras의 Sequential API를 사용하여 신경망 모델을 정의하기 위해 가져옴.\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# 신경망의 구성 요소인 Dense(완전 연결 층)와 Flatten(2D 데이터를 1D로 평탄화) 레이어를 가져옴. (예 32,32,3 크기 이미지) -> (32*32*3)으로 변환\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# 모델 학습 중 체크포인트 저장(성능이 향상될때마다 저장기능) 및 학습 조기 종료(성능이 향상되지 않으면 종료)(Early Stopping)를 위해 콜백 가져옴.\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n"
      ],
      "metadata": {
        "id": "TVGmUfWDWaEg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # CIFAR-10 데이터 세트를 불러옵니다.\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "-8xO0Ls-WbDs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 확인합니다.\n",
        "\n",
        "print(train_images.shape, train_labels.shape)\n",
        "print(test_images.shape, test_labels.shape)\n",
        "\n",
        "# train_images -> 모델이 이 이미지를 보고 패턴을 학습\n",
        "# train_labels -> 각 이미지에 해당 하는 정답 라벨 -> 이걸 통해서 이미지를 분류하는법을 배우게 됨\n",
        "\n",
        "# 훈련완료 후에는\n",
        "\n",
        "# test_images와 test_labels 테스트 데이터셋을 사용\n",
        "# 모델이 얼마나 잘 학습되었는지 평가할 수 있음\n",
        "\n",
        "#훈련 데이터 이미지수 ,가로픽셀,가로픽셀, 채널색상수)\n",
        "#테스트 이미지 데이터, 가로,세로크기,색상 채널"
      ],
      "metadata": {
        "id": "qJs5w0t4Wc9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bbb67a-384c-4757-953b-540eebb8a2c3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화된 이미지 데이터를 하나 확인\n",
        "\n",
        "train_images[0]"
      ],
      "metadata": {
        "id": "oKb8X5k5We1V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e00896ae-b4e5-4742-c035-60d2d0cbc3b2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-5b5e69bb-a565-436e-b0be-36038255c1db\" class=\"ndarray_repr\"><pre>ndarray (32, 32, 3) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,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\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[[ 59,  62,  63],\n",
              "        [ 43,  46,  45],\n",
              "        [ 50,  48,  43],\n",
              "        ...,\n",
              "        [158, 132, 108],\n",
              "        [152, 125, 102],\n",
              "        [148, 124, 103]],\n",
              "\n",
              "       [[ 16,  20,  20],\n",
              "        [  0,   0,   0],\n",
              "        [ 18,   8,   0],\n",
              "        ...,\n",
              "        [123,  88,  55],\n",
              "        [119,  83,  50],\n",
              "        [122,  87,  57]],\n",
              "\n",
              "       [[ 25,  24,  21],\n",
              "        [ 16,   7,   0],\n",
              "        [ 49,  27,   8],\n",
              "        ...,\n",
              "        [118,  84,  50],\n",
              "        [120,  84,  50],\n",
              "        [109,  73,  42]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[208, 170,  96],\n",
              "        [201, 153,  34],\n",
              "        [198, 161,  26],\n",
              "        ...,\n",
              "        [160, 133,  70],\n",
              "        [ 56,  31,   7],\n",
              "        [ 53,  34,  20]],\n",
              "\n",
              "       [[180, 139,  96],\n",
              "        [173, 123,  42],\n",
              "        [186, 144,  30],\n",
              "        ...,\n",
              "        [184, 148,  94],\n",
              "        [ 97,  62,  34],\n",
              "        [ 83,  53,  34]],\n",
              "\n",
              "       [[177, 144, 116],\n",
              "        [168, 129,  94],\n",
              "        [179, 142,  87],\n",
              "        ...,\n",
              "        [216, 184, 140],\n",
              "        [151, 118,  84],\n",
              "        [123,  92,  72]]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-5b5e69bb-a565-436e-b0be-36038255c1db button').onclick = (e) => {\n",
              "        document.querySelector('#id-5b5e69bb-a565-436e-b0be-36038255c1db').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-5b5e69bb-a565-436e-b0be-36038255c1db button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인을 위해 출력\n",
        "plt.figure(figsize=(1, 1))\n",
        "plt.imshow(train_images[32])"
      ],
      "metadata": {
        "id": "oum8p8UuWfwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "2fdf4543-a1d2-4876-c956-3d8da2aaa5c5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7bb9f13ba710>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 100x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화를 위해 255로 나누어 줌\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "#print(train_images[0])\n",
        "#print(test_images[0])"
      ],
      "metadata": {
        "id": "_azRThgLWhPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "932227ce-1760-4d1f-d644-4ea74d310a0f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.23137255 0.24313725 0.24705882]\n",
            "  [0.16862745 0.18039216 0.17647059]\n",
            "  [0.19607843 0.18823529 0.16862745]\n",
            "  ...\n",
            "  [0.61960784 0.51764706 0.42352941]\n",
            "  [0.59607843 0.49019608 0.4       ]\n",
            "  [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843137 0.07843137]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509804 0.21568627]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215686 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941176 0.19607843]\n",
            "  [0.47058824 0.32941176 0.19607843]\n",
            "  [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.81568627 0.66666667 0.37647059]\n",
            "  [0.78823529 0.6        0.13333333]\n",
            "  [0.77647059 0.63137255 0.10196078]\n",
            "  ...\n",
            "  [0.62745098 0.52156863 0.2745098 ]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            " [[0.70588235 0.54509804 0.37647059]\n",
            "  [0.67843137 0.48235294 0.16470588]\n",
            "  [0.72941176 0.56470588 0.11764706]\n",
            "  ...\n",
            "  [0.72156863 0.58039216 0.36862745]\n",
            "  [0.38039216 0.24313725 0.13333333]\n",
            "  [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            " [[0.69411765 0.56470588 0.45490196]\n",
            "  [0.65882353 0.50588235 0.36862745]\n",
            "  [0.70196078 0.55686275 0.34117647]\n",
            "  ...\n",
            "  [0.84705882 0.72156863 0.54901961]\n",
            "  [0.59215686 0.4627451  0.32941176]\n",
            "  [0.48235294 0.36078431 0.28235294]]]\n",
            "[[[0.61960784 0.43921569 0.19215686]\n",
            "  [0.62352941 0.43529412 0.18431373]\n",
            "  [0.64705882 0.45490196 0.2       ]\n",
            "  ...\n",
            "  [0.5372549  0.37254902 0.14117647]\n",
            "  [0.49411765 0.35686275 0.14117647]\n",
            "  [0.45490196 0.33333333 0.12941176]]\n",
            "\n",
            " [[0.59607843 0.43921569 0.2       ]\n",
            "  [0.59215686 0.43137255 0.15686275]\n",
            "  [0.62352941 0.44705882 0.17647059]\n",
            "  ...\n",
            "  [0.53333333 0.37254902 0.12156863]\n",
            "  [0.49019608 0.35686275 0.1254902 ]\n",
            "  [0.46666667 0.34509804 0.13333333]]\n",
            "\n",
            " [[0.59215686 0.43137255 0.18431373]\n",
            "  [0.59215686 0.42745098 0.12941176]\n",
            "  [0.61960784 0.43529412 0.14117647]\n",
            "  ...\n",
            "  [0.54509804 0.38431373 0.13333333]\n",
            "  [0.50980392 0.37254902 0.13333333]\n",
            "  [0.47058824 0.34901961 0.12941176]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.26666667 0.48627451 0.69411765]\n",
            "  [0.16470588 0.39215686 0.58039216]\n",
            "  [0.12156863 0.34509804 0.5372549 ]\n",
            "  ...\n",
            "  [0.14901961 0.38039216 0.57254902]\n",
            "  [0.05098039 0.25098039 0.42352941]\n",
            "  [0.15686275 0.33333333 0.49803922]]\n",
            "\n",
            " [[0.23921569 0.45490196 0.65882353]\n",
            "  [0.19215686 0.4        0.58039216]\n",
            "  [0.1372549  0.33333333 0.51764706]\n",
            "  ...\n",
            "  [0.10196078 0.32156863 0.50980392]\n",
            "  [0.11372549 0.32156863 0.49411765]\n",
            "  [0.07843137 0.25098039 0.41960784]]\n",
            "\n",
            " [[0.21176471 0.41960784 0.62745098]\n",
            "  [0.21960784 0.41176471 0.58431373]\n",
            "  [0.17647059 0.34901961 0.51764706]\n",
            "  ...\n",
            "  [0.09411765 0.30196078 0.48627451]\n",
            "  [0.13333333 0.32941176 0.50588235]\n",
            "  [0.08235294 0.2627451  0.43137255]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터셋(0~45000)과 검증 데이터셋(45001~50000)으로 나누어 줌\n",
        "\n",
        "#훈련 데이터셋\n",
        "val_images = train_images[45000:]\n",
        "val_labels = train_labels[45000:]\n",
        "\n",
        "#검증 데이터셋\n",
        "train_images = train_images[:45000]\n",
        "train_labels = train_labels[:45000]\n",
        "\n",
        "#왜 이런식으로 하는지??\n",
        "# 모델이 훈련 데이터에만 맞춰져서 잘 동작하는 것처럼 보일 수 있기 때문에,\n",
        "# 검증 데이터를 통해 모델이 실제로 얼마나 잘 일반화 되는지 확인 할 수 있음\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Ctm3g_xbWiL0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 생성\n",
        "\n",
        "mlp_model = Sequential([\n",
        "    Flatten(input_shape=(32, 32, 3)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "seX12YeDWjWV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 구조를 확인합니다.\n",
        "\n",
        "mlp_model.summary()"
      ],
      "metadata": {
        "id": "uPKPPWCoWkbg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "58fcf4c7-d6a4-4c62-cd13-d7fbb4d97045"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,573,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,738,890\u001b[0m (6.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,738,890</span> (6.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,738,890\u001b[0m (6.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,738,890</span> (6.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 훈련합니다.\n",
        "\n",
        "mlp_model.fit(train_images, train_labels, epochs=5, validation_data=(val_images, val_labels))"
      ],
      "metadata": {
        "id": "q2r3LUvkWlgg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "3e8400b5-1b74-4874-8bb9-dbb6f069ff5a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You must call `compile()` before using the model.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4d85ce6e37be>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델을 훈련합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/trainer.py\u001b[0m in \u001b[0;36m_assert_compile_called\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    999\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"calling `{method_name}()`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_symbolic_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You must call `compile()` before using the model."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가합니다.\n",
        "\n",
        "mlp_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "McheaxXWWmTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망을 활용한 이미지 분류"
      ],
      "metadata": {
        "id": "oxYLdZ9va7jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout"
      ],
      "metadata": {
        "id": "nO1qF_jlbBMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 만듭니다.\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    Flatten(),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "    ])"
      ],
      "metadata": {
        "id": "fpjV3jZVbCcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 구조를 확인합니다.\n",
        "\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "L3HkFcoLbDU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 컴파일합니다.\n",
        "\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NLqcXB02bEei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping, ModelCheckpoint 콜백을 정의합니다.\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "save_best_only = ModelCheckpoint('best_cifar10_cnn_model.h5', save_best_only=True)"
      ],
      "metadata": {
        "id": "N43sWa-6bFYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 학습시킵니다.\n",
        "# 중간에 학습이 중단되는 게 맞습니다.\n",
        "\n",
        "history = cnn_model.fit(train_images, train_labels, batch_size=512, epochs=100, validation_data=(val_images, val_labels), callbacks=[early_stopping, save_best_only])"
      ],
      "metadata": {
        "id": "FY91gNn2bGBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 스텝의 학습 손실과 검증 손실을 그래프로 나타냅니다.\n",
        "\n",
        "plt.plot(history.history['loss'], 'b--')\n",
        "plt.plot(history.history['val_loss'], 'r--')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LmCDtIajbHt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 평가합니다.\n",
        "\n",
        "cnn_model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "Y-lWM_xYbJBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 레이블 배열을 생성합니다.\n",
        "\n",
        "predicted_labels = cnn_model.predict(test_images)\n",
        "predicted_labels.shape"
      ],
      "metadata": {
        "id": "JL17f5z8bJzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 배열의 최대 값의 색인을 뽑아내어 예측 레이블로 사용합니다.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "predicted_labels = tf.argmax(predicted_labels, axis=1)\n",
        "predicted_labels"
      ],
      "metadata": {
        "id": "iCL0XwukbK1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_name = {\n",
        "    0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer',\n",
        "    5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truck'\n",
        "}"
      ],
      "metadata": {
        "id": "N56BPPHXbLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_images를 시각화하여 test_labels와 predicted_labels를 비교합니다.\n",
        "# test_labels와 predicted_labels가 다를 때, xlabel의 색깔을 빨강색으로 변경합니다.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
        "    xlabel = f\"{label_to_name[int(test_labels[i][0])]} ({label_to_name[int(predicted_labels[i])]})\"\n",
        "    plt.xlabel(xlabel, color='red' if test_labels[i][0] != predicted_labels[i] else 'black')"
      ],
      "metadata": {
        "id": "_r0EndrAbNB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 객체 인식"
      ],
      "metadata": {
        "id": "IE-MWBxZbORB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Lilcob/test_colab/main/three%20young%20man.jpg\n",
        "\n",
        "# 이미지 로드\n",
        "image_path = \"/content/three young man.jpg\"\n",
        "image = cv2.imread(image_path)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# 하르 캐스케이드 로드\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "# 얼굴 탐지\n",
        "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "print(faces)"
      ],
      "metadata": {
        "id": "_yEKjLjPbQFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # 탐지된 얼굴에 사각형 그리기\n",
        "for (x, y, w, h) in faces:\n",
        "    cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "# 결과 표시\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')  # 축 정보 숨기기\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zjiF9twQbRPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}